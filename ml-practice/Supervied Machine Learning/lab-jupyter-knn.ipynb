{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0cdecb-1339-4d2c-a908-125172340917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "# Evaluation metrics related methods\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_recall_fscore_support, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7bb374-8dab-46f9-b469-69cce5265502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a random seed to reproduce any random process\n",
    "rs = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d427e3-d9e5-4fbe-9d95-9c1bcd4bbab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore any deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb241c52-bace-49ab-a63e-726b642d0bfb",
   "metadata": {},
   "source": [
    "## Load and explore the tumor sample dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afbc05f-a98b-4d1e-854f-0a091d401a6f",
   "metadata": {},
   "source": [
    "We first load the dataset `tumor.csv` as a Pandas dataframe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1808e96e-30af-4f82-807b-2402854f53b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datast in csv format\n",
    "dataset_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML241EN-SkillsNetwork/labs/datasets/tumor.csv\"\n",
    "tumor_df = pd.read_csv(dataset_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db087835-22c6-4d5f-b9e5-f4cebfe2ff16",
   "metadata": {},
   "source": [
    "Then, let's quickly take a look at the head of the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd940dd6-3509-405c-9b5c-b958fbfa1536",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8abe804-9ff2-4a8d-a8d6-13acaa66629c",
   "metadata": {},
   "source": [
    "And, display its columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d7be8d-1241-4166-93f1-ab8661c796fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68261e2-2d55-4108-8e3c-51f0f40a6714",
   "metadata": {},
   "source": [
    "Each observation in this dataset contains lab test results about a tumor sample, such as clump or shapes. Based on these lab test results or features, we want to build a classification model to predict if this tumor sample is malicious (cancer) or benign. The target variable `y` is specified in the `Class` column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e8c789-cb73-4314-82c6-3d225b999ce2",
   "metadata": {},
   "source": [
    "Then, let's split the dataset into input `X` and output `y`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ac9b76-66bc-4779-b6e3-9d522cc62edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tumor_df.iloc[:, :-1]\n",
    "y = tumor_df.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa4e8fb-fc39-40f8-9494-eaa45ce7cde5",
   "metadata": {},
   "source": [
    "And, we first check the statistics summary of features in `X`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7b030c-df02-4f5e-90be-dd06eb94c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e0cc7-5fe5-4803-93cc-e1452a9a305c",
   "metadata": {},
   "source": [
    "As we can see from the above cell output, all features are numeric and ranged between 1 to 10. This is very convenient as we do not need to scale the feature values as they are already in the same range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad110fc2-c361-414c-836d-e6ebf0222d2e",
   "metadata": {},
   "source": [
    "Next, let's check the class distribution of output `y`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261a1bbd-0244-4308-8196-764ca01d17fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7834a43a-731f-4a9e-8574-dfd774a0ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts().plot.bar(color=['green', 'red'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab5d7bf-ddf7-4a4a-bfba-81ddd60f25fc",
   "metadata": {},
   "source": [
    "We have about 65% benign tumors (`Class = 0`) and 35% cancerous tumors (`Class = 1`), which is not a very imbalanced class distribution. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e371515-f8a3-4a9f-9c84-170fd8729ffc",
   "metadata": {},
   "source": [
    "## Split training and testing datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4dd15f-7d9d-413a-8aed-5368faee5fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 80% as training dataset\n",
    "# and 20% as testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state = rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af99a6f-e505-4c8b-a8a2-de107fc8edb3",
   "metadata": {},
   "source": [
    "## Train and evaluate a KNN classifier with the number of neighbors set to 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52801c62-50f6-42b2-b0c6-3e0c4e670374",
   "metadata": {},
   "source": [
    "Training a KNN classifier is very similar to training other classifiers in `sklearn`, we first need to define a `KNeighborsClassifier` object. Here we use `n_neighbors=2` argument to specify how many neighbors will be used for prediction, and we keep other arguments to be their default values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1040ed56-e27e-4fca-b897-690e0878707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a KNN classifier with `n_neighbors=2`\n",
    "knn_model = KNeighborsClassifier(n_neighbors=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a7ab63-2a6e-480a-aa8d-306334eb9ae7",
   "metadata": {},
   "source": [
    "Then we can train the model with `X_train` and `y_train`, and we use ravel() method to convert the data frame `y_train` to a vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4509284a-94cb-48f0-a3af-256d3d5eb6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a045c817-467a-49b2-a077-d0f8ef778e5f",
   "metadata": {},
   "source": [
    "And, we can make predictions on the `X_test` dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3a69d-e0bd-4afc-a7e3-4e2714011aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02e7ca-84ed-4273-9b50-2945d2ec8c48",
   "metadata": {},
   "source": [
    "To evaluate the KNN classifier, we provide a pre-defined method to return the commonly used evaluation metrics such as accuracy, recall, precision, f1score, and so on, based on the true classes in the 'y_test' and model predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926470c8-dc9c-4df9-ada8-87851ba22b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(yt, yp):\n",
    "    results_pos = {}\n",
    "    results_pos['accuracy'] = accuracy_score(yt, yp)\n",
    "    precision, recall, f_beta, _ = precision_recall_fscore_support(yt, yp, average='binary')\n",
    "    results_pos['recall'] = recall\n",
    "    results_pos['precision'] = precision\n",
    "    results_pos['f1score'] = f_beta\n",
    "    return results_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1371c29a-be23-4359-965e-1c4d78f80371",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_metrics(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ab57d-dbff-4217-994a-0b16c44765fe",
   "metadata": {},
   "source": [
    "We can see that there is a great classification performance on the tumor sample dataset. This means the KNN model can effectively recognize cancerous tumors.\n",
    "Next, it's your turn to try a different number of neighbors to see if we could get even better performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9823831c-a34f-4143-9d69-c287b3bdabd9",
   "metadata": {},
   "source": [
    "## Coding exercise: Train and evaluate a KNN classifier with number of neighbors set to 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bf53f9-261c-4388-bddd-a963bec2ad15",
   "metadata": {},
   "source": [
    "First, define a KNN classifier with KNeighborsClassifier class:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f992f041-b220-4f8e-8044-c2c79c6d31a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b005c354-90d0-475c-8503-e418990591b4",
   "metadata": {},
   "source": [
    "Then train the model with `X_train` and `y_train`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df310929-a63a-4913-b7c3-763844f335c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47438149-29c6-4391-8217-8003c4450eae",
   "metadata": {},
   "source": [
    "And, make predictions on `X_test` dataframe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b0f387-7f4a-432c-b0bd-964a53a0a20e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2f65f5d-d8f4-48fc-96cc-7441f05cacb5",
   "metadata": {},
   "source": [
    "At last, you can evaluate your KNN model with provided `evaluate_metrics()` method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738dfd85-a51c-4297-a326-f5c4f295a9e8",
   "metadata": {},
   "source": [
    "<details><summary>Click here for a sample solution</summary>\n",
    "\n",
    "```python\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "preds = model.predict(X_test)\n",
    "evaluate_metrics(y_test, preds)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33161f7d-39aa-48d5-ad44-9435def6c572",
   "metadata": {},
   "source": [
    "## Tune the number of neighbors to find the optmized one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7385d859-09f3-48b7-8ee6-150a5ce5e98c",
   "metadata": {},
   "source": [
    "OK, you may wonder which `n_neighbors` argument may give you the best classification performance. We can try different `n_neighbors` (the K value) and check which `K` gives the best classification performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb1eabf-3c7e-413e-9d1f-8c1e94ce16bd",
   "metadata": {},
   "source": [
    "Here we could try K from 1 to 50, and store the aggregated `f1score` for each k into a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3120f948-2918-4ace-b000-17175b613819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try K from 1 to 50\n",
    "max_k = 50\n",
    "# Create an empty list to store f1score for each k\n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2250d9a-0394-427a-9c32-ba6983fdf196",
   "metadata": {},
   "source": [
    "Then we will train 50 KNN classifiers with K ranged from 1 to 50.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70fe201-789d-4b96-86ff-1a2b6f0e6db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1, max_k + 1):\n",
    "    # Create a KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Train the classifier\n",
    "    knn = knn.fit(X_train, y_train.values.ravel())\n",
    "    preds = knn.predict(X_test)\n",
    "    # Evaluate the classifier with f1score\n",
    "    f1 = f1_score(preds, y_test)\n",
    "    f1_scores.append((k, round(f1_score(y_test, preds), 4)))\n",
    "# Convert the f1score list to a dataframe\n",
    "f1_results = pd.DataFrame(f1_scores, columns=['K', 'F1 Score'])\n",
    "f1_results.set_index('K')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b2c71b-82e9-4d6f-a23b-8dfbcb292459",
   "metadata": {},
   "source": [
    "This is a long list and different to analysis, so let's visualize the list using a linechart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94db8a0-5e9f-4457-ba84-66a4208ccba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot F1 results\n",
    "ax = f1_results.plot(figsize=(12, 12))\n",
    "ax.set(xlabel='Num of Neighbors', ylabel='F1 Score')\n",
    "ax.set_xticks(range(1, max_k, 2));\n",
    "plt.ylim((0.85, 1))\n",
    "plt.title('KNN F1 Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0bd30e-fffc-4780-acc7-8adfab2ec0c5",
   "metadata": {},
   "source": [
    "As we can see from the F1 score linechart, the best `K` value is 5 with about `0.9691` f1score.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "prev_pub_hash": "91c30c910c7945a998d3c1082d0ce375c10c5bb00d6c93723d696311d8d8b37b"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
