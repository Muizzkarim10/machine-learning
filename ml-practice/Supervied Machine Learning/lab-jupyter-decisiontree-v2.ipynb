{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae7340e6-0942-45c6-bc3a-798d724cc277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "# Evaluation metrics related methods\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_recall_fscore_support, precision_score, recall_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848a109-aa01-48ce-a8eb-4276c27d06b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c6877b-1631-4413-ace4-34f77e1e0148",
   "metadata": {},
   "source": [
    "## Load and explore the tumor dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068df87c-6239-41b3-b12a-88592eb26cb3",
   "metadata": {},
   "source": [
    "First, let's load the tumor dataset as a Pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4030a009-43ed-4058-92ca-975e7d2f0929",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML241EN-SkillsNetwork/labs/datasets/tumor.csv\"\n",
    "tumor_df = pd.read_csv(dataset_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b729f76b-282b-4014-9b11-049b8b73c43a",
   "metadata": {},
   "source": [
    "And check its dataframe head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f4dfba-2d85-453c-9d84-d0e2f6f9b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fd1da8-7007-43fc-893c-d3ae29efbfe0",
   "metadata": {},
   "source": [
    "Each observation in this dataset contains lab tests results about a tumor sample, such as clump or shapes. Based on these lab test results or features, we want to build a classification model to predict if this tumor sample is malicious (cancer) and benign. The target variable `y` is specified in the `Class` column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46eae03-6248-4a8f-9614-5132dc21cd5a",
   "metadata": {},
   "source": [
    "Then, let's split the dataframe into train and testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92433d50-bc2f-4c2e-9a9f-9d70ca599a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input features\n",
    "X = tumor_df.iloc[:, :-1]\n",
    "# Get the target variable\n",
    "y = tumor_df.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb610c-103c-4e6a-868f-205c30d1211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state = rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9ac6f9-d1ce-4124-9bd6-890772aa6809",
   "metadata": {},
   "source": [
    "### Train a default decision tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a1cff2-934c-43ca-b983-d23eae5e386e",
   "metadata": {},
   "source": [
    "Training a decision classifier is very straightforward with `sklearn`, we first need to define a `DecisionTreeClassifier` object. In the first step, we will use all the default arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb427176-bdbc-4edd-b9e4-d391a6608d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a decision tree with all default arguments\n",
    "model = DecisionTreeClassifier(random_state=rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837f4821-fda9-413e-92fa-919dc6450721",
   "metadata": {},
   "source": [
    "Then we can train the decision tree model with training and testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a3426-a9c7-471a-b8d7-83a0328f18c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679b8832-0d37-411f-85fb-786d4ef7a7ff",
   "metadata": {},
   "source": [
    "And make predictions on the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1774d-0ed0-4121-907e-960c08210fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bd18e2-864c-40db-ab2d-b8d1b0a02612",
   "metadata": {},
   "source": [
    "Here we also provided a utility method to evaluate the trained decision tree model and output some standard evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874bb677-1651-4a77-83df-b6a064e34c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(yt, yp):\n",
    "    results_pos = {}\n",
    "    results_pos['accuracy'] = accuracy_score(yt, yp)\n",
    "    precision, recall, f_beta, _ = precision_recall_fscore_support(yt, yp, average='binary')\n",
    "    results_pos['recall'] = recall\n",
    "    results_pos['precision'] = precision\n",
    "    results_pos['f1score'] = f_beta\n",
    "    return results_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f45ed6-2c2f-4bba-afda-0971cca2bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_metrics(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63cb6c6-b283-4be0-acd6-abfa72b2bce1",
   "metadata": {},
   "source": [
    "Now we can see that the trained decision model has very good classification results on the testing data, with a very high F1 score around 0.94. Next, let's try to visualize and interpret the trained decision tree model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d350adca-ad4a-4e7c-874b-9ba65c6645e3",
   "metadata": {},
   "source": [
    "## Visualize the trained decision tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db6f237-284d-4294-a070-73f898e64458",
   "metadata": {},
   "source": [
    "We will be using the `tree.plot_tree()` method provided by `sklearn` to quickly plot any decision tree model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9399172e-94e9-471e-b488-9402deabd8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_tree(model, feature_names):\n",
    "    plt.subplots(figsize=(25, 20)) \n",
    "    tree.plot_tree(model, \n",
    "                       feature_names=feature_names,  \n",
    "                       filled=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c3492-2ac8-4bc9-8ab2-32e4466ffcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213782b3-9969-43cb-9b28-d0b4e822c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_tree(model, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47574d9-6fed-47c1-90c5-89c5c594b829",
   "metadata": {},
   "source": [
    "And you should see a relatively complex decision tree model being plotted. First, you may notice the decision tree is color-labeled, orange node means a majority of samples in the node belong to `Class 0` and blue node means a majority of samples in the node belong to `Class 1`, and white node means it has an equal amount of `Class 0` and `Class 1` samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e598c0-59a4-4911-a06b-772082369c00",
   "metadata": {},
   "source": [
    "Because the tree is very big, so the rules and split threshold on each node are very difficult to see. In addition, big decision trees may easily bring large variance and cause overfitting. Next, let's try to build simplified decision trees, and hopefully the simplified decision trees may generate even better results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06db180-562e-408f-a990-7bc629c83d43",
   "metadata": {},
   "source": [
    "## Cutomize the decision tree model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5812b3-382e-48af-9ecc-7e77a29a6b88",
   "metadata": {},
   "source": [
    "The `DecisionTreeClassifier` has many arguments (model hyperparameters) that can be customized and eventually tune the generated decision tree classifiers. Among these arguments, there are three commonly tuned arguments as follows:\n",
    "- criterion: `gini` or `entropy`, which specifies which criteria to be used when splitting a tree node\n",
    "- max_depth: a numeric value to specify the max depth of the tree. Larger tree depth normally means larger model complexity\n",
    "- min_samples_leaf: The minimal number of samples in leaf nodes. Larger samples in leaf nodes will tend to generate simpler trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e01e498-f838-499a-a7f8-dd4c7d5207c9",
   "metadata": {},
   "source": [
    "Let's first try the following hyperparameter values:\n",
    "- criterion = 'entropy'\n",
    "- max_depth = 10\n",
    "- min_samples_leaf=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6604e83-59ee-4b90-83d1-3fb702fa8d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = 'entropy'\n",
    "# max_depth = 10\n",
    "# min_samples_leaf=3\n",
    "custom_model = DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_leaf=3, random_state=rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b06d578-6822-409c-961d-ae56465c9790",
   "metadata": {},
   "source": [
    "And let's train and evaluate the customized model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055120d7-c330-49c8-9af7-7722dedcac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.fit(X_train, y_train.values.ravel())\n",
    "preds = custom_model.predict(X_test)\n",
    "evaluate_metrics(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a575251-9ecc-44a2-b28f-bacce94b472a",
   "metadata": {},
   "source": [
    "Its F1 score has increased to 0.946 now, which seems better than the previous default decision tree model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff3d88b-ccef-4789-a223-4c6383f507ff",
   "metadata": {},
   "source": [
    "Then, let's visualize the custom model using plot_decision_tree() utility method we created in the previous step:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c88d9-b43d-4bcd-bf1a-32f9c0c45d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision tree\n",
    "plot_decision_tree(custom_model, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6669c8de-3a70-4305-b913-2985becd15b6",
   "metadata": {},
   "source": [
    "As you can see the tuned decision tree above is much simpler than the default decision tree model. We can see from each node, it's split feature and threshold, and entropy difference before and after a split.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac15cd54-d943-421c-8010-65a6a9bb3e26",
   "metadata": {},
   "source": [
    "## Coding exercise: build and visualize a decision tree with criterion='gini', max_depth = 15, and min_samples_leaf=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ccab81-8311-4dc6-bbba-eae2f55c690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a customized decision tree\n",
    "custom_model = DecisionTreeClassifier(criterion='gini', max_depth=15, min_samples_leaf=5, random_state=rs)\n",
    "custom_model.fit(X_train, y_train.values.ravel())\n",
    "preds = custom_model.predict(X_test)\n",
    "evaluate_metrics(y_test, preds)\n",
    "# Plot the decision tree\n",
    "plot_decision_tree(custom_model, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9147854e-943e-42d4-ae8b-77fa0b03eec9",
   "metadata": {},
   "source": [
    "## Tune hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc09a1b-48ee-42dd-89e1-c15fd1ea729b",
   "metadata": {},
   "source": [
    "Lastly, let's try to find the optimized hyperparameters, which can produce the highest F1 score, via GridSearch cross-validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b3430d-9c9d-4a45-b846-5aa08df1ba51",
   "metadata": {},
   "source": [
    "We define a `params_grid` dict object to contain the parameter candidates:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad290d5-8ad3-4407-a884-cf190b19cbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [5, 10, 15, 20],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdd5f46-022d-450d-9b68-6ef6a4f97401",
   "metadata": {},
   "source": [
    "Then we create a default decision tree classifier to be tuned:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637c5a4-d61e-4346-9d2a-8d3c1644a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c86054-d351-41f8-b8b4-7e5409b2c8ee",
   "metadata": {},
   "source": [
    "Ok, now we can use the `GridSearchCV` to search the best parameters generating the highest F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb771f68-3c4c-48f4-9ba8-87aaef51efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = model, \n",
    "                        param_grid = params_grid, \n",
    "                        scoring='f1',\n",
    "                        cv = 5, verbose = 1)\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16058b3a-067d-4602-bb75-2c1c691e5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75a7b45-8b15-4817-afd0-a8831f309f44",
   "metadata": {},
   "source": [
    "So the best parameters are criterion=`gini`, max_depth=10, and min_samples_leaf=5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71e0cd9-1780-4051-90d1-7b478ae9278f",
   "metadata": {},
   "source": [
    "## Coding exercise: build and visualize a decision tree with the best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512a3736-ed4d-4fbe-9b31-9d9293d50868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a customized decision tree\n",
    "custom_model = DecisionTreeClassifier(criterion='gini', max_depth=10, min_samples_leaf=5, random_state=rs)\n",
    "custom_model.fit(X_train, y_train.values.ravel())\n",
    "preds = custom_model.predict(X_test)\n",
    "evaluate_metrics(y_test, preds)\n",
    "# Plot the decision tree\n",
    "plot_decision_tree(custom_model, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd566f3c-2da3-43ff-90ad-04b20d25b42a",
   "metadata": {},
   "source": [
    "<!--## Change Log--!>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b399ed-9029-40e8-9ea2-1ee812f9bb94",
   "metadata": {},
   "source": [
    "<!--|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2021-9-23|1.0|Yan|Created the initial version||2022-2-9|1.1|Steve Hord|QA pass|\n",
    "--!>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "prev_pub_hash": "dfd22e9a2a1908e3f2acd5c71412aedc96165115b8f7428d64bde6eadd79d182"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
